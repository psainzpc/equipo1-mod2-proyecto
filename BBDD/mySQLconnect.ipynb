{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos todos los csv. Vamos a pasar los datos a workbench unificado en este archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irene, en este archivo hemos intentado hacer por separado (me refiero a fuera de cada archivo para tenerlo unifiao en este)lo de concatenar los csv. El de spotify no lo hemos tocado y los otros dos no nos han funcionado, creemos que por la ruta. Compruebalo porfis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCATENAR CSVs\n",
    "#### pasar a lista de tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPOTIFY \n",
    "\n",
    "# Ruta a la carpeta que contiene los archivos CSV\n",
    "ruta_carpeta = '/Users/psainz/ADALAB/PROYECTOS/proyecto-da-promo-k-modulo-2-team-1/CSVs/spotify_csv'\n",
    "\n",
    "# Usar glob para encontrar todos los archivos CSV\n",
    "archivos_csv_sp = glob.glob(ruta_carpeta + \"/*.csv\")\n",
    "\n",
    "# Leer y concatenar los archivos\n",
    "df_concatenado_1 = pd.concat([pd.read_csv(archivo) for archivo in archivos_csv_sp], ignore_index=True)\n",
    "\n",
    "print(df_concatenado_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_sp_concat = list(df_concatenado_1.itertuples(index=False, name=None))\n",
    "lista_sp_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUSICBRAINZ\n",
    "\n",
    "# Ruta a la carpeta que contiene los archivos CSV\n",
    "ruta_carpeta_mb = '/Users/psainz/ADALAB/PROYECTOS/proyecto-da-promo-k-modulo-2-team-1/CSVs/musicbrainz_csv'\n",
    "\n",
    "# Usar glob para encontrar todos los archivos CSV\n",
    "archivos_csv_mb = glob.glob(ruta_carpeta_mb + \"/*.csv\")\n",
    "\n",
    "# Leer y concatenar los archivos\n",
    "df_concatenado_2 = pd.concat([pd.read_csv(archivo) for archivo in archivos_csv_mb], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "print(df_concatenado_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_mb_concat = list(df_concatenado_2.itertuples(index=False, name=None))\n",
    "lista_mb_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASTFM\n",
    "# Ruta a la carpeta que contiene los archivos CSV\n",
    "ruta_carpeta = '/Users/psainz/ADALAB/PROYECTOS/proyecto-da-promo-k-modulo-2-team-1/CSVs/lastFM_csv'\n",
    "\n",
    "# Usar glob para encontrar todos los archivos CSV\n",
    "archivos_csv_lfm = glob.glob(ruta_carpeta + \"/*.csv\")\n",
    "\n",
    "# Leer y concatenar los archivos\n",
    "df_concatenado_3 = pd.concat([pd.read_csv(archivo) for archivo in archivos_csv_lfm], ignore_index=True)\n",
    "\n",
    "print(df_concatenado_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_lfm_concat = list(df_concatenado_3.itertuples(index=False, name=None))\n",
    "lista_lfm_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MySQL connector\n",
    "#### subir listas de tuplas a BBDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cnx = mysql.connector.connect(user='root', password='AlumnaAdalab',\n",
    "                              host='127.0.0.1',\n",
    "                              database='musicStream',  auth_plugin='mysql_native_password')\n",
    "# en caso de que no lo consigas por que hay algún error entonces ...\n",
    "except mysql.connector.Error as err:\n",
    "\n",
    "  # si es un error con la contraseña devuelveme un mensaje de acceso denegado ya que tenemos problemas con la contraseña\n",
    "  if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "    print(\"Something is wrong with your user name or password\")\n",
    "  \n",
    "  # si el error no tiene que ver con la contraseña, puede ser porque la base de datos no exista, devuelveme un mensaje de que la base de datos no existe\n",
    "  elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "    print(\"Database does not exist\")\n",
    "  \n",
    "  # si no es por ninguno de los errores anteriores, printeame cual es el error que estoy teniendo en mi conexión\n",
    "  else:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2307 registro/s insertado/s.\n"
     ]
    }
   ],
   "source": [
    "#SPOTIFY\n",
    "\n",
    "mycursor = cnx.cursor()\n",
    "sql = \"INSERT IGNORE INTO spotify (song, artist, genre, t_type, release_year, y_year) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "val = lista_sp_concat\n",
    "\n",
    "try: \n",
    "    mycursor.executemany(sql, val)\n",
    "    cnx.commit()\n",
    "    print(mycursor.rowcount, \"registro/s insertado/s.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008 registro/s insertado/s.\n"
     ]
    }
   ],
   "source": [
    "#MUSICBRAINZ\n",
    "\n",
    "mycursor = cnx.cursor()\n",
    "sql = \"INSERT IGNORE INTO musicbrainz (artist, origin_country, origin_area, begin_act, end_act) VALUES (%s, %s, %s, %s, %s)\"\n",
    "val = lista_mb_concat\n",
    "\n",
    "try: \n",
    "    mycursor.executemany(sql, val)\n",
    "    cnx.commit()\n",
    "    print(mycursor.rowcount, \"registro/s insertado/s.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754 registro/s insertado/s.\n"
     ]
    }
   ],
   "source": [
    "#LASTFM\n",
    "mycursor = cnx.cursor()\n",
    "sql = \"INSERT IGNORE INTO lastfm (artist, bio, listeners, playcount, similar_artists) VALUES (%s, %s, %s, %s, %s)\"\n",
    "val = lista_lfm_concat\n",
    "\n",
    "try: \n",
    "    mycursor.executemany(sql, val)\n",
    "    cnx.commit()\n",
    "    print(mycursor.rowcount, \"registro/s insertado/s.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
